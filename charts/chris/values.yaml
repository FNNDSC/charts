# This file is for cutomizing how chris is deployed.

# Name
#####################

nameOverride: ""
fullnameOverride: ""


# Stuff you can typically ignore
#####################

imagePullSecrets: []

# Global settings
#####################

global:
  # storage class to use for persistent volume claims
  storageClass: ""

  # optional security context to apply to all pods
  # podSecurityContext:
  #   runAsUser: 123456
  #   runAsGroup: 789


# Not used
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""


# Ingress and HTTPS
ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: Prefix
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# OpenShift route
route:
  enabled: false
  host: chart-example.local
  tls:
    termination: edge
    insecureEdgeTerminationPolicy: Redirect
    destinationCACertificate: ''


# ChRIS automatic admin account
#####################

chris_admin:
  username: khris
  email: noreply@babyMRI.org
  # If no password is set, then a random password is created for you.
  # password:

# ChRIS Backend
#####################
cube:
  image:
    repository: ghcr.io/fnndsc/cube
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  # Use inter-pod affinity as a workaround for using a ReadWriteOnce PersistentVolumeClaim
  enablePodAffinityWorkaround: false

  # Prefix to use for job names submitted to Kubernetes. Ideally, this should be unique for each CUBE instance.
  # The default behavior is to use the release name as the job prefix.
  # jobPrefix: ""

  # Configuration
  #####################
  config:
    # smaller values increases responsiveness at the cost of resource usage and possibly concurrency bugs
    CUBE_CELERY_POLL_INTERVAL: "5.0"
    # HTTP server security settings
    DJANGO_ALLOWED_HOSTS: "*"  # note: * is okay if OpenShift router or k8s igress is validating host header
    DJANGO_CORS_ALLOW_ALL_ORIGINS: "true"
    DJANGO_CORS_ALLOWED_ORIGINS: ""
    DJANGO_SECURE_PROXY_SSL_HEADER: ""
    DJANGO_USE_X_FORWARDED_HOST: "false"
    # enable LDAP login
    AUTH_LDAP: "false"
    # AUTH_LDAP_SERVER_URI: "ldap://192.168.0.29:389"
    # AUTH_LDAP_BIND_DN: "cn=admin,dc=fnndsc,dc=org"
    # AUTH_LDAP_USER_SEARCH_ROOT: "dc=fnndsc,dc=org"

  ## Additional secret environment variables for CUBE
  # secrets:
  #   AUTH_LDAP_BIND_PASSWORD: "admin1234"

  # Set of default plugins to register with the coupled pfcon (if .pfcon.enabled)
  # Plugins which CUBE is hard-coded to depend on should be listed here.
  # To add plugins for general use, see https://chrisproject.org/docs/tutorials/upload_plugin
  plugins:
    - https://cube.chrisproject.org/api/v1/plugins/1/   # pl-dircopy
    - https://cube.chrisproject.org/api/v1/plugins/2/   # pl-tsdircopy
    - https://cube.chrisproject.org/api/v1/plugins/3/   # pl-topologicalcopy

  # Storage
  #####################
  # Persistent volume for CUBE files
  storage:
    # In the default configuration, the volume is managed by pfcon's subchart, so leave this as "enabled: false"
    enabled: false
    size: 100Gi
    accessModes: [ "ReadWriteOnce" ]
    # storageClass: ""

  # Resources
  #####################
  workerMains:
    ## Resources for the main worker.
    ## It requires a large memory allocation due to an inefficient implementation.
    ## Recommended value is x4 the size of the largest anticipated plugin instance output directory.
    resources:
      requests:
        memory: 3814Mi
        cpu: 1
      limits:
        memory: 3814Mi
        cpu: 1

  workerPeriodic:
    ## Resources for the periodic worker.
    ## Default values should be okay. Memory request may be further reduced to ~400Mi.
    resources:
      requests:
        memory: 1Gi
        cpu: 250m
      limits:
        memory: 1Gi
        cpu: 250m

  server:
    service:
      type: ClusterIP
      port: 8000
      # nodePort:
      ## nodePortHost does nothing. It is simply used to print the URL of CUBE in the NOTES
      # nodePortHost:
    
    # In the command, you can customize the number of workers, timeout, etc.
    # *do not* change the value for -b
    # *do not* change the positional argument "config.wsgi:application"
    # You may change -t (timeout in seconds) and/or -w (workers)
    command: ["gunicorn", "-b", "0.0.0.0:8000", "-w", "4", "-t", "3600", "config.wsgi:application"]
    ## resources for the HTTP server (WSGI).
    ## Default values should be okay. About 256Mi of memory is needed per idle worker.
    resources:
      requests:
        memory: 2Gi
        cpu: 1
      limits:
        memory: 2Gi
        cpu: 1

# Database
#####################

# [SUBCHART] PostgreSQL packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/postgresql#parameters
postgresql:

  # no reason to change these values
  auth:
    database: "chris"
    username: "chris"

  # one of: [standalone, replication]
  # Replication is supported, see upstream README.md for configuration.
  architecture: standalone

  primary:
    # Primary database instance resource requests
    resources:
      requests:
        memory: 1Gi
        cpu: 1
      limits:
        memory: 1Gi
        cpu: 1

    persistence:
      enabled: true
      size: 8Gi

    # Defer control of security configurations to OpenShift
    podSecurityContext:
      enabled: false
    containerSecurityContext:
      enabled: false
  volumePermissions:
    enabled: false
  shmVolume:
    enabled: false

# [SUBCHART] RabbitMQ packaged by Bitnami
# https://github.com/bitnami/charts/tree/main/bitnami/rabbitmq#parameters
rabbitmq:

  # No reason to change these values.
  #
  # Whether or not to set a password for RabbitMQ depends on your threat model.
  # The RabbitMQ service does not receive ingress traffic, the password appears
  # here in values.yaml due to limitations of how Helm charts share variables
  # with subcharts.
  auth:
    username: "chris"
    password: "chris1234"

  persistence:
    enabled: true
    size: 1Gi

  # Defer control of security configurations to OpenShift
  podSecurityContext:
    enabled: false
  containerSecurityContext:
    enabled: false
  volumePermissions:
    enabled: false

# pfcon: ChRIS compute resource
#####################

pfcon:
  enabled: true

  name: "innetwork"
  description: "Kubernetes cluster compute resource"
  replicaCount: 1
  podAnnotations: {}

  service:
    type: ClusterIP
    port: 5005

  nodeSelector: {}

  # Storage space for CUBE files should be configured here.
  # It is recommended to allocate as much space as possible for CUBE files.
  storage:
    existingClaim: ""
    size: 100Gi
    accessModes: [ "ReadWriteOnce" ]
    # storageClass:

  pfcon:
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 384Mi

    workers: 4
    workerTimeout: 3600

    # pfcon configuration
    # Recommended to keep as-is
    config:
      innetwork: true
      storageEnv: filesystem

  pman:
    # It is unnecessary to increase pman's resources to above the minimum because
    # pman doesn't do anything besides sending and receiving HTTP requests.
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 1Gi

    workers: 4
    workerTimeout: 30

    # pman configuration
    # https://github.com/fnndsc/pman#environment-variables
    # SECRET_KEY, CONTAINER_ENV, STORAGE_TYPE, VOLUME_NAME, and CONTAINER_USER are handled automatically
    config:
      JOB_LABELS: chrisproject.org/job=plugininstance
      ENABLE_HOME_WORKAROUND: "yes"
      REMOVE_JOBS: "yes"
      IGNORE_LIMITS: "no"

    # Set securityContext of containers created by pman to have the same securityContext as .global.podSecurityContext
    # or the default fnndsc/cube container user, so that the container user can write to the shared volume's filesystem.
    # Should be disabled on OpenShift.
    setSecurityContext: true


# pfdcm: ChRIS PACS connector
#####################

pfdcm:
  enabled: false
  image:
    repository: ghcr.io/fnndsc/pfdcm
    pullPolicy: IfNotPresent
    tag: "3.1.22"
  podAnnotations: {}
  service:
    enabled: true
    type: ClusterIP
    port: 4005
    # nodePort:
  # OpenShift route
  route:
    enabled: false
    host: chart-example.local
    tls:
      termination: edge
      insecureEdgeTerminationPolicy: Redirect
      destinationCACertificate: ''
  maxWorkers: 1
  resources:
    limits:
      cpu: 1
      memory: 1Gi
    requests:
      cpu: 1
      memory: 1Gi
  # TODO CAN I DELETE PFDCM'S STORAGE?
  persistence:
    enabled: true
    # existingClaim: ""
    # storageClass:
    size: 1Gi
    accessModes: [ "ReadWriteOnce" ]
  # TODO DELETE ME TOO
  # Does the same as .Values.cube.enablePodAffinityWorkaround, but for pfdcm's satellite
  # services: pfdcmListener, pfdcmDicomweb. Likely necessary when using RWO volumes.
  enablePodAffinityWorkaround: false

  # If Orthanc is enabled, then "aet" will be the aet of pfdcm's listener.
  aet: "ChRIS"

  # Additional pfdcm configuration. Usually, you'll want to leave this empty.
  # pfdcm will be preconfigured with the CUBE and Orthanc of this chart.
  # If this pfdcm interacts with multiple CUBEs or multiple PACS servers,
  # add them here.
  additionalConfig:
    cube: {}
      # local:
      #   url: https://cube.example.org/api/v1/
      #   username: pfdcm
      #   password: pfdcm1234
    storage: {}
      # local:
      #   storagetype: fs
      #   storepath: /files
    pacs:
      services: {}
        # orthanc:
        #   info:
        #     aet: CHRISLOCAL
        #     aet_listener: ORTHANC
        #     aec: ORTHANC
        #     serverIP: orthanc
        #     serverPort: 4242

  # DICOM listener for pfdcm. Enabled when pfdcm is enabled.
  listener:
    image:
      repository: ghcr.io/fnndsc/oxidicom
      pullPolicy: IfNotPresent
      tag: "0.1.0"
    podAnnotations: {}
    # The PACS server must be configured to push to this service.
    # If using Orthanc, the Helm chart will help you validate your
    # configuration of Orthanc's modailities to include this service.
    service:
      enabled: true
      type: ClusterIP
      port: 11111
      # nodePort: 30033
    replicas: 1
    config:
      threads: 4
      # pacs_name: "PACSNAMEOVERRIDE"
    ## manual configuration of OpenTelemetry
    # env:
    #   - name: OTEL_RESOURCE_ATTRIBUTES
    #     value: service.name=oxidicom
    #   - name: OTEL_EXPORTER_OTLP_ENDPOINT
    #     value: http://tempo:4318
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 500m
        memory: 512Mi

# PACS server
orthanc:
  # If Orthanc is enabled, it is recommended to also enable pfdcm.
  enabled: false
  podAnnotations: {}
  podSecurityContext: {}
    # fsGroup: 2000
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000
  # Orthanc HTTP API and web app
  service:
    enabled: true
    type: ClusterIP
    port: 8042
    # nodePort:
  # PACS server
  dicomService:
    enabled: true
    type: ClusterIP
    port: 4242
    # nodePort:
  resources:
    limits:
      cpu: 1
      memory: 4Gi
    requests:
      cpu: 1
      memory: 4Gi
  config:
    # The logical name of this instance of Orthanc. This one is
    # displayed in Orthanc Explorer and at the URI "/system".
    name: "Orthanc"
    # Enable the transparent compression of the DICOM instances
    storageCompression: false
    # Action to take when the maximum storage is reached.
    # By default, the patients are recycled ("Recycle" mode).
    # In "Reject" mode, the sender will receive a 0xA700 DIMSE status code
    # if the instance was sent through C-Store, a 507 HTTP status code
    # if using the REST API and a 0xA700 Failure reason when using
    # DicomWeb Stow-RS 
    # Allowed values: "Recycle", "Reject"
    # (new in Orthanc 1.11.2)
    maximumStorageMode: Reject
    # Maximum size of the storage cache in MB.  The storage cache
    # is stored in RAM and contains a copy of recently accessed
    # files (written or read).  A value of "0" indicates the cache
    # is disabled.  (new in Orthanc 1.10.0)
    maximumStorageCacheSize: 0

    # The DICOM Application Entity Title
    dicomAet: "ORTHANC"
    # Check whether the called AET corresponds during a DICOM request
    dicomCheckCalledAet: false

    # The default encoding that is assumed for DICOM files without
    # "SpecificCharacterSet" DICOM tag, and that is used when answering
    # C-Find requests (including worklists). The allowed values are
    # "Ascii", "Utf8", "Latin1", "Latin2", "Latin3", "Latin4",
    # "Latin5", "Cyrillic", "Windows1251", "Arabic", "Greek", "Hebrew",
    # "Thai", "Japanese", and "Chinese".
    defaultEncoding: "Latin1"

    # Set the timeout (in seconds) after which the DICOM associations
    # are closed by the Orthanc SCP (server) if no further DIMSE
    # command is received from the SCU (client).
    dicomScpTimeout: 30

    # The timeout (in seconds) after which the DICOM associations are
    # considered as closed by the Orthanc SCU (client) if the remote
    # DICOM SCP (server) does not answer.
    dicomScuTimeout: 10

    # Whether or not the password protection is enabled
    AuthenticationEnabled: true

    # The list of the registered users. Because Orthanc uses HTTP
    # Basic Authentication, the passwords are stored as plain text.
    registeredUsers: {}

    # The list of the known DICOM modalities
    #
    # A fourth parameter is available to enable patches for a
    # specific PACS manufacturer. The allowed values are currently
    # "Generic" (default value), "StoreScp" (storescp tool from
    # DCMTK), "ClearCanvas", "MedInria", "Dcm4Chee", "SyngoVia",
    # "AgfaImpax" (Agfa IMPAX), "EFilm2" (eFilm version 2), and
    # "Vitrea". This parameter is case-sensitive.
    dicomModalities:
      # !!!IMPORTANT!!!
      # To use in combination with pfdcm, you MUST define a modality for
      # `.Values.pfdcm.aet`
      "ChRIS": [ "ChRIS", "NAME-oxidicom", 11111 ]
      # "clearcanvas" : [ "CLEARCANVAS", "192.168.1.1", 104, "ClearCanvas" ]

    # Whether Orthanc monitors its metrics (new in Orthanc 1.5.4). If
    # set to "true", the metrics can be retrieved at
    # "/tools/metrics-prometheus" formetted using the Prometheus
    # text-based exposition format.
    metricsEnabled: true

  ohif:
    enabled: true
    # BTW, it's impossible to configure Orthanc's OHIF to connect with pfdcm-dicomweb.

    # OHIF custom config file
    # https://orthanc.uclouvain.be/book/plugins/ohif.html#user-configuration-of-ohif
    # userConfiguration: |
    #   window.config = {
    #     extensions: [],
    #     modes: []
    #   }

  persistence:
    storage:
      size: 1Gi
      # storageClass: my-storage-class
      accessModes: [ ReadWriteOnce ]
    index:
      size: 1Gi
      # storageClass: my-storage-class
      accessModes: [ ReadWriteOnce ]
